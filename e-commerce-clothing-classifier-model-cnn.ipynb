{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0dadf0",
   "metadata": {
    "papermill": {
     "duration": 0.004356,
     "end_time": "2024-10-09T10:18:02.326791",
     "exception": false,
     "start_time": "2024-10-09T10:18:02.322435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c80d236",
   "metadata": {
    "papermill": {
     "duration": 0.003541,
     "end_time": "2024-10-09T10:18:02.334191",
     "exception": false,
     "start_time": "2024-10-09T10:18:02.330650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this project, we implement a Convolutional Neural Network (CNN) using PyTorch to classify images from the FashionMNIST dataset. FashionMNIST is a widely-used dataset consisting of 70,000 grayscale images, each of size 28x28, divided into 10 categories of fashion-related items (e.g., shirts, shoes, bags). The objective is to train a CNN model to automatically classify these images into their respective categories.\n",
    "\n",
    "The model’s architecture includes multiple convolutional layers, ReLU activation, and max-pooling, followed by fully connected layers and dropout for regularization. After training, we evaluate the model using key metrics such as accuracy, precision, and recall to measure its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85667dec",
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-10-09T10:18:02.343109Z",
     "iopub.status.busy": "2024-10-09T10:18:02.342752Z",
     "iopub.status.idle": "2024-10-09T10:18:26.555235Z",
     "shell.execute_reply": "2024-10-09T10:18:26.554124Z"
    },
    "executionCancelledAt": null,
    "executionTime": 6920,
    "jupyter": {
     "outputs_hidden": true
    },
    "lastExecutedAt": 1728464294100,
    "lastExecutedByKernel": "491b5782-01bb-4def-aaca-f634a354e98c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "!pip install torchmetrics\n!pip install torchvision",
    "outputsMetadata": {
     "0": {
      "height": 544,
      "type": "stream"
     }
    },
    "papermill": {
     "duration": 24.219641,
     "end_time": "2024-10-09T10:18:26.557741",
     "exception": false,
     "start_time": "2024-10-09T10:18:02.338100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.4.2)\r\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.4.0)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.11.7)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (70.0.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.15.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.4.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (2024.6.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e10616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T10:18:26.568495Z",
     "iopub.status.busy": "2024-10-09T10:18:26.568148Z",
     "iopub.status.idle": "2024-10-09T10:18:32.909657Z",
     "shell.execute_reply": "2024-10-09T10:18:32.908847Z"
    },
    "executionCancelledAt": null,
    "executionTime": 5597,
    "lastExecutedAt": 1728464299699,
    "lastExecutedByKernel": "491b5782-01bb-4def-aaca-f634a354e98c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall",
    "papermill": {
     "duration": 6.349485,
     "end_time": "2024-10-09T10:18:32.912027",
     "exception": false,
     "start_time": "2024-10-09T10:18:26.562542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978bcfb9",
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-10-09T10:18:32.922348Z",
     "iopub.status.busy": "2024-10-09T10:18:32.921931Z",
     "iopub.status.idle": "2024-10-09T10:18:44.371487Z",
     "shell.execute_reply": "2024-10-09T10:18:44.370431Z"
    },
    "executionCancelledAt": null,
    "executionTime": 1330,
    "jupyter": {
     "outputs_hidden": true
    },
    "lastExecutedAt": 1728464301030,
    "lastExecutedByKernel": "491b5782-01bb-4def-aaca-f634a354e98c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     },
     "1": {
      "height": 38,
      "type": "stream"
     },
     "2": {
      "height": 122,
      "type": "stream"
     },
     "3": {
      "height": 38,
      "type": "stream"
     },
     "4": {
      "height": 122,
      "type": "stream"
     },
     "5": {
      "height": 38,
      "type": "stream"
     },
     "6": {
      "height": 122,
      "type": "stream"
     },
     "7": {
      "height": 38,
      "type": "stream"
     },
     "8": {
      "height": 59,
      "type": "stream"
     }
    },
    "papermill": {
     "duration": 11.457891,
     "end_time": "2024-10-09T10:18:44.374555",
     "exception": false,
     "start_time": "2024-10-09T10:18:32.916664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:03<00:00, 7304798.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 142781.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 2598420.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 11837871.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea135a26",
   "metadata": {
    "papermill": {
     "duration": 0.008035,
     "end_time": "2024-10-09T10:18:44.392010",
     "exception": false,
     "start_time": "2024-10-09T10:18:44.383975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Architecture\n",
    "\n",
    "#### The CNN model consists of the following components:\n",
    "\n",
    "#### 1. Convolutional Layers:\n",
    "   Three convolutional layers with 32, 64, and 128 filters, respectively, each followed by a ReLU activation function and max-pooling for downsampling. These layers allow the model to extract hierarchical features from the input images.\n",
    "#### 2.Fully Connected Layers:\n",
    "   After the convolutional layers, the output is flattened and passed through two fully connected layers with 256 and 128 neurons, respectively. Dropout is applied to reduce overfitting.\n",
    "#### 3.Output Layer:\n",
    "   The final output layer consists of 10 neurons (one for each class in FashionMNIST), followed by softmax (implicitly applied during loss computation) to output class probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50027027",
   "metadata": {
    "papermill": {
     "duration": 0.007745,
     "end_time": "2024-10-09T10:18:44.407673",
     "exception": false,
     "start_time": "2024-10-09T10:18:44.399928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Process\n",
    "\n",
    "The model is trained on the FashionMNIST training dataset using the Adam optimizer with a learning rate of 0.001. The CrossEntropyLoss function is used as the loss criterion since it is suitable for multi-class classification problems. The training loop runs for 10 epochs, with the model performing gradient descent and backpropagation on each batch of images.\n",
    "\n",
    "During each epoch, the loss is accumulated and averaged across the training batches, providing feedback on the model’s performance during training. The model is moved to the GPU (if available) to accelerate computations.\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "After training, the model is evaluated on the test set, where we calculate accuracy, precision, and recall for each of the 10 classes. These metrics provide insight into the model’s performance in terms of correctly classifying images and handling imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4435f612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T10:18:44.425561Z",
     "iopub.status.busy": "2024-10-09T10:18:44.425111Z",
     "iopub.status.idle": "2024-10-09T10:21:16.478643Z",
     "shell.execute_reply": "2024-10-09T10:21:16.477613Z"
    },
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    },
    "papermill": {
     "duration": 152.073297,
     "end_time": "2024-10-09T10:21:16.488833",
     "exception": false,
     "start_time": "2024-10-09T10:18:44.415536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/10], Loss: 0.5623613644415127\n",
      "Epoch [2/10], Loss: 0.3257112097717933\n",
      "Epoch [3/10], Loss: 0.2721219977765068\n",
      "Epoch [4/10], Loss: 0.23980968208836595\n",
      "Epoch [5/10], Loss: 0.2161986966655135\n",
      "Epoch [6/10], Loss: 0.19593229614245866\n",
      "Epoch [7/10], Loss: 0.17976405663586564\n",
      "Epoch [8/10], Loss: 0.16342382995423668\n",
      "Epoch [9/10], Loss: 0.14986353732351618\n",
      "Epoch [10/10], Loss: 0.1406423020532041\n",
      "Finished Training\n",
      "Test Accuracy: 91.73%\n",
      "Per-class Precision: [0.87234043 0.99195171 0.81672598 0.91666667 0.87316562 0.98993964\n",
      " 0.80463576 0.95348837 0.97235933 0.98155738]\n",
      "Per-class Recall: [0.861 0.986 0.918 0.935 0.833 0.984 0.729 0.984 0.985 0.958]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the CNN class\n",
    "class FashionMNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNIST_CNN, self).__init__()\n",
    "        # First convolutional block: Conv -> ReLU -> MaxPool\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.flatten = nn.Flatten()  # Flatten before the FC layers\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(128, 10)  # 10 output classes\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    # Define the forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = self.maxpool3(self.relu3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu4(self.fc1(x)))\n",
    "        x = self.dropout(self.relu5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Load FashionMNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = FashionMNIST_CNN().to(device)  # Move the model to the GPU if available\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop (keeping epochs low as per instruction)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to the GPU\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader)}\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "# Make predictions on the test set and store in 'predictions'\n",
    "predictions = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images = images.to(device)  # Move test images to the GPU\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())  # Store predictions and move them back to CPU\n",
    "\n",
    "# Convert predictions to a list\n",
    "predictions = list(predictions)\n",
    "\n",
    "# Calculate accuracy, precision, and recall\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        all_labels.extend(labels.cpu().numpy())  # Store true labels\n",
    "\n",
    "# Accuracy calculation\n",
    "correct = sum([pred == label for pred, label in zip(predictions, all_labels)])\n",
    "accuracy = correct / len(all_labels) * 100\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Precision and recall calculation\n",
    "precision = precision_score(all_labels, predictions, average=None)\n",
    "recall = recall_score(all_labels, predictions, average=None)\n",
    "\n",
    "print(f\"Per-class Precision: {precision}\")\n",
    "print(f\"Per-class Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09afc8",
   "metadata": {
    "papermill": {
     "duration": 0.008629,
     "end_time": "2024-10-09T10:21:16.506722",
     "exception": false,
     "start_time": "2024-10-09T10:21:16.498093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The CNN model successfully classifies FashionMNIST images with an accuracy of **91.67%**, demonstrating its effectiveness in extracting features from the input data and generalizing well to unseen data. The high precision and recall values across most classes indicate that the model performs well in distinguishing between different categories.\n",
    "\n",
    "While the model performs well, further improvements could be made by experimenting with different architectures, hyperparameters, or optimization strategies. Additionally, increasing the number of epochs or using data augmentation techniques may further enhance the model’s performance.\n",
    "\n",
    "This project demonstrates the power of CNNs for image classification tasks and highlights the capabilities of PyTorch for deep learning implementations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 198.454327,
   "end_time": "2024-10-09T10:21:18.037630",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-09T10:17:59.583303",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
